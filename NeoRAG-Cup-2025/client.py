import streamlit as st
import base64
import random
import pandas as pd
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from reranker_search import Reranker
from llm_api import LLM
from llm_local import LLM as LLM_local
from hybrid_search import HybridSearch

# --- PH·∫¶N C·∫§U H√åNH TRANG V√Ä BI·ªÇU T∆Ø·ª¢NG TI√äU ƒê·ªÄ ---

# ƒê·ªçc v√† m√£ h√≥a ·∫£nh sang Base64
image_path = "Img/logopro.png"  # ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n n√†y ƒë√∫ng
encoded_string = None
try:
    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode()
except FileNotFoundError:
    print(f"L·ªñI: Kh√¥ng t√¨m th·∫•y t·ªáp t·∫°i ƒë∆∞·ªùng d·∫´n '{image_path}'. Vui l√≤ng ki·ªÉm tra l·∫°i.")

ICON_DATA_URL = f"data:image/png;base64,{encoded_string}"
ICON_PATH = "Img/logopro.png"

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="ProPTIT Chatbot",
    page_icon=ICON_PATH,
    layout="centered"
)

# Hi·ªÉn th·ªã ti√™u ƒë·ªÅ v·ªõi icon
st.markdown(f"""
<h1 style="display: flex; align-items: center; justify-content: center;">
    <img src="{ICON_DATA_URL}" alt="Bi·ªÉu t∆∞·ª£ng CLB" style="width: 32px; height: 32px; margin-right: 15px; vertical-align: middle;">
    ProPTIT Chatbot üí¨
</h1>
""", unsafe_allow_html=True)

st.markdown("Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi h·ªá th·ªëng h·ªèi ƒë√°p t·ª± ƒë·ªông c·ªßa CLB! H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ CLB ƒë·ªÉ nh·∫≠n th√¥ng tin.")

# --- DANH S√ÅCH C√ÇU H·ªéI G·ª¢I √ù ---
SUGGESTED_QUESTIONS = [
    "CLB ProPTIT c√≥ nh·ªØng ban n√†o?",
    "L√†m th·∫ø n√†o ƒë·ªÉ tr·ªü th√†nh th√†nh vi√™n c·ªßa CLB?",
    "L·ªãch sinh ho·∫°t c·ªßa CLB nh∆∞ th·∫ø n√†o?",
    "ProPTIT c√≥ nh·ªØng ho·∫°t ƒë·ªông ngo·∫°i kh√≥a n√†o?",
    "M√¨nh c√≥ c·∫ßn bi·∫øt l·∫≠p tr√¨nh tr∆∞·ªõc khi tham gia kh√¥ng?",
    "Quy·ªÅn l·ª£i khi tr·ªü th√†nh th√†nh vi√™n CLB l√† g√¨?"
]

# --- C√ÅC H√ÄM LOAD MODEL (Kh√¥ng thay ƒë·ªïi) ---
@st.cache_resource
def load_model():
    llm_name = "openai/gpt-oss-20b"
    base_data_path = "CLB_PROPTIT.csv"
    llm_model = LLM(llm_name, base_data_path)
    return llm_model

llm_model = load_model()

@st.cache_resource
def load_hybrid_search(local):
    base_data_path = "CLB_PROPTIT.csv"
    train_data_path  = "train_data_proptit.xlsx"
    reranker_path ="Vietnamese_Reranker_finetuned"
    if local:
        llm_name = "Qwen/Qwen3-0.6B"
        llm = LLM_local(llm_name, base_data_path)
    else:
        llm_name = "openai/gpt-oss-20b"
        llm = LLM(llm_name, base_data_path)
    bm25_type = "BM25L"
    reranker_model =Reranker(AutoModelForSequenceClassification.from_pretrained(reranker_path),
                            AutoTokenizer.from_pretrained(reranker_path),
                            base_data_path
                            )
    hybrid_search = HybridSearch(bm25_type, reranker_model, llm, base_data_path, train_data_path)
    return hybrid_search

hybrid_search = load_hybrid_search(local=False)

# --- GIAO DI·ªÜN CH√çNH ---

# Kh·ªüi t·∫°o l·ªãch s·ª≠ chat
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Sidebar v·ªõi c√°c g·ª£i √Ω v√† c√†i ƒë·∫∑t
with st.sidebar:
    use_rag_search = st.toggle("S·ª≠ d·ª•ng t√¨m ki·∫øm t√†i li·ªáu üîç", value=True, key="use_rag_toggle")
    
    st.subheader("üí° G·ª£i √Ω cho b·∫°n:")
    # Kh·ªüi t·∫°o c√¢u h·ªèi g·ª£i √Ω n·∫øu ch∆∞a c√≥
    if "suggested_questions_this_session" not in st.session_state:
        st.session_state.suggested_questions_this_session = random.sample(SUGGESTED_QUESTIONS, 3)
    
    # Khi m·ªôt n√∫t ƒë∆∞·ª£c nh·∫•p, l∆∞u c√¢u h·ªèi v√†o m·ªôt key T·∫†M TH·ªúI
    for question in st.session_state.suggested_questions_this_session:
        if st.button(question, key=f"btn_{question}", use_container_width=True):
            st.session_state.clicked_query = question # S·ª≠ d·ª•ng key kh√°c, kh√¥ng ph·∫£i "user_query"
            st.rerun()

# Hi·ªÉn th·ªã tr·∫°ng th√°i t√¨m ki·∫øm
if use_rag_search:
    st.info("T√¨m ki·∫øm ƒëang ƒë∆∞·ª£c b·∫≠t ‚úÖ")
else:
    st.warning("T√¨m ki·∫øm th√¥ng minh ƒëang b·ªã t·∫Øt ‚ùå")

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for message in st.session_state.chat_history:
    avatar = "ü§ñ" if message["role"] == "assistant" else "üë§"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# --- LOGIC X·ª¨ L√ù TRUY V·∫§N (ƒê√£ s·ª≠a l·ªói) ---
user_query = None

# ∆Øu ti√™n x·ª≠ l√Ω c√¢u h·ªèi t·ª´ n√∫t b·∫•m tr∆∞·ªõc
if "clicked_query" in st.session_state and st.session_state.clicked_query:
    user_query = st.session_state.clicked_query
    del st.session_state.clicked_query # X√≥a key t·∫°m th·ªùi sau khi l·∫•y gi√° tr·ªã

# L·∫•y c√¢u h·ªèi t·ª´ √¥ chat input
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ CLB...‚ùì"):
    user_query = prompt

# N·∫øu c√≥ c√¢u h·ªèi t·ª´ m·ªôt trong hai ngu·ªìn, th√¨ x·ª≠ l√Ω
if user_query:
    # Th√™m c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
    st.session_state.chat_history.append({"role": "user", "content": user_query})

    # Hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng ngay l·∫≠p t·ª©c
    with st.chat_message("user", avatar="üë§"):
        st.markdown(user_query)

    # X·ª≠ l√Ω logic chatbot
    with st.spinner(text="ƒêang suy nghƒ©...",show_time=True):
        try:
            if use_rag_search: 
                doc_ids = hybrid_search.search(user_query, 60, 7, 7)
                prompt_for_llm = llm_model.generate_answer_prompt(user_query, list(doc_ids.keys()))
                ai_answer = llm_model.generate_response(prompt_for_llm, st.session_state.chat_history)
            else: 
                ai_answer = llm_model.generate_response(user_query, st.session_state.chat_history)
            
            # Th√™m c√¢u tr·∫£ l·ªùi c·ªßa bot v√†o l·ªãch s·ª≠
            st.session_state.chat_history.append({"role": "assistant", "content": ai_answer})

        except Exception as e:
            error_message = f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}"
            st.error(error_message)
            st.session_state.chat_history.append({"role": "assistant", "content": error_message})
    
    # Ch·∫°y l·∫°i to√†n b·ªô script ƒë·ªÉ hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi m·ªõi c·ªßa bot
    st.rerun()
